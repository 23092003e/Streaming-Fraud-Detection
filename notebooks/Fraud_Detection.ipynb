{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m geodesic\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Data Processing\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "\n",
    "# Modeling\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, when, mean,expr, avg, stddev\n",
    "from pyspark.sql.functions import lag, coalesce, lit\n",
    "from pyspark.sql.functions import to_date, date_format, to_timestamp\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, unix_timestamp\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "True\n",
      "NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)  # Check pytorch version\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Data Invetigating and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "train_path = r'D:/Data Science/Big Data Technology/Project/Streaming-Fraud-Detection/Streaming-Fraud-Detection/data/raw/fraudTrain.csv'\n",
    "test_path = r'D:/Data Science/Big Data Technology/Project/Streaming-Fraud-Detection/Streaming-Fraud-Detection/data/raw/fraudTest.csv'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_train = pd.read_csv(train_path, low_memory=False, index_col=0)\n",
    "df_test = pd.read_csv(test_path, low_memory=False, index_col=0)\n",
    "\n",
    "# Merge data\n",
    "df = pd.concat([df_train, df_test],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the transaction date to datetime\n",
    "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "df[\"dob\"] = pd.to_datetime(df[\"dob\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>gender</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>F</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>F</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>1978-06-21</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>M</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>1962-01-19</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>M</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>1939</td>\n",
       "      <td>Patent attorney</td>\n",
       "      <td>1967-01-12</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>375534208663984</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>M</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>Dance movement psychotherapist</td>\n",
       "      <td>1986-03-28</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trans_date_trans_time            cc_num                            merchant  \\\n",
       "0   2019-01-01 00:00:18  2703186189652095          fraud_Rippin, Kub and Mann   \n",
       "1   2019-01-01 00:00:44      630423337322     fraud_Heller, Gutmann and Zieme   \n",
       "2   2019-01-01 00:00:51    38859492057661                fraud_Lind-Buckridge   \n",
       "3   2019-01-01 00:01:16  3534093764340240  fraud_Kutch, Hermiston and Farrell   \n",
       "4   2019-01-01 00:03:06   375534208663984                 fraud_Keeling-Crist   \n",
       "\n",
       "        category     amt gender      lat      long  city_pop  \\\n",
       "0       misc_net    4.97      F  36.0788  -81.1781      3495   \n",
       "1    grocery_pos  107.23      F  48.8878 -118.2105       149   \n",
       "2  entertainment  220.11      M  42.1808 -112.2620      4154   \n",
       "3  gas_transport   45.00      M  46.2306 -112.1138      1939   \n",
       "4       misc_pos   41.96      M  38.4207  -79.4629        99   \n",
       "\n",
       "                                 job        dob   unix_time  merch_lat  \\\n",
       "0          Psychologist, counselling 1988-03-09  1325376018  36.011293   \n",
       "1  Special educational needs teacher 1978-06-21  1325376044  49.159047   \n",
       "2        Nature conservation officer 1962-01-19  1325376051  43.150704   \n",
       "3                    Patent attorney 1967-01-12  1325376076  47.034331   \n",
       "4     Dance movement psychotherapist 1986-03-28  1325376186  38.674999   \n",
       "\n",
       "   merch_long  is_fraud  \n",
       "0  -82.048315         0  \n",
       "1 -118.186462         0  \n",
       "2 -112.154481         0  \n",
       "3 -112.561071         0  \n",
       "4  -78.632459         0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary columns for modeling\n",
    "df = df.drop(['first', 'last', 'street', 'city', 'state', 'zip', 'trans_num'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the age of the cardholder\n",
    "df['age'] = df['trans_date_trans_time'].dt.year - df['dob'].dt.year\n",
    "\n",
    "# Extract hour, day, and month\n",
    "df['hour'] = df['trans_date_trans_time'].dt.hour\n",
    "df['day_of_week'] = df['trans_date_trans_time'].dt.dayofweek\n",
    "df['month'] = df['trans_date_trans_time'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function JavaWrapper.__del__ at 0x000001AF9B12A700>\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Data Science\\Big Data Technology\\Project\\Streaming-Fraud-Detection\\Streaming-Fraud-Detection\\venv\\lib\\site-packages\\pyspark\\ml\\wrapper.py\", line 53, in __del__\n",
      "    if SparkContext._active_spark_context and self._java_obj is not None:\n",
      "AttributeError: 'RandomForestClassifier' object has no attribute '_java_obj'\n",
      "Exception ignored in: <function JavaWrapper.__del__ at 0x000001AF9B12A700>\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Data Science\\Big Data Technology\\Project\\Streaming-Fraud-Detection\\Streaming-Fraud-Detection\\venv\\lib\\site-packages\\pyspark\\ml\\wrapper.py\", line 53, in __del__\n",
      "    if SparkContext._active_spark_context and self._java_obj is not None:\n",
      "AttributeError: 'RandomForestClassifier' object has no attribute '_java_obj'\n"
     ]
    }
   ],
   "source": [
    "# Calculate the distance between home and merchant locations\n",
    "#df['distance'] = df.apply(lambda row: geodesic((row['lat'], row['long']), (row['merch_lat'], row['merch_long'])).miles, axis=1)\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "@udf(\"double\")\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    return geodesic((lat1, lon1), (lat2, lon2)).km\n",
    "\n",
    "df = df.withColumn(\"distance\", calculate_distance(df.lat, df.long, df.merch_lat, df.merch_long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount vs average amount by category\n",
    "df['amt_vs_category_avg'] = df['amt'] / df.groupby('category')['amt'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>gender</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>age</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>distance</th>\n",
       "      <th>amt_vs_category_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>F</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48.947783</td>\n",
       "      <td>0.061984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>F</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.775736</td>\n",
       "      <td>0.919323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>M</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67.172035</td>\n",
       "      <td>3.431553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>M</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>1939</td>\n",
       "      <td>Patent attorney</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>59.455974</td>\n",
       "      <td>0.708915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>375534208663984</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>M</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>Dance movement psychotherapist</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48.282030</td>\n",
       "      <td>0.669470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trans_date_trans_time            cc_num                            merchant  \\\n",
       "0   2019-01-01 00:00:18  2703186189652095          fraud_Rippin, Kub and Mann   \n",
       "1   2019-01-01 00:00:44      630423337322     fraud_Heller, Gutmann and Zieme   \n",
       "2   2019-01-01 00:00:51    38859492057661                fraud_Lind-Buckridge   \n",
       "3   2019-01-01 00:01:16  3534093764340240  fraud_Kutch, Hermiston and Farrell   \n",
       "4   2019-01-01 00:03:06   375534208663984                 fraud_Keeling-Crist   \n",
       "\n",
       "        category     amt gender      lat      long  city_pop  \\\n",
       "0       misc_net    4.97      F  36.0788  -81.1781      3495   \n",
       "1    grocery_pos  107.23      F  48.8878 -118.2105       149   \n",
       "2  entertainment  220.11      M  42.1808 -112.2620      4154   \n",
       "3  gas_transport   45.00      M  46.2306 -112.1138      1939   \n",
       "4       misc_pos   41.96      M  38.4207  -79.4629        99   \n",
       "\n",
       "                                 job   unix_time  merch_lat  merch_long  \\\n",
       "0          Psychologist, counselling  1325376018  36.011293  -82.048315   \n",
       "1  Special educational needs teacher  1325376044  49.159047 -118.186462   \n",
       "2        Nature conservation officer  1325376051  43.150704 -112.154481   \n",
       "3                    Patent attorney  1325376076  47.034331 -112.561071   \n",
       "4     Dance movement psychotherapist  1325376186  38.674999  -78.632459   \n",
       "\n",
       "   is_fraud  age  hour  month  day_of_week   distance  amt_vs_category_avg  \n",
       "0         0   31     0      1            1  48.947783             0.061984  \n",
       "1         0   41     0      1            1  18.775736             0.919323  \n",
       "2         0   57     0      1            1  67.172035             3.431553  \n",
       "3         0   52     0      1            1  59.455974             0.708915  \n",
       "4         0   33     0      1            1  48.282030             0.669470  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['day', 'dob'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1852394 entries, 0 to 1852393\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   trans_date_trans_time  datetime64[ns]\n",
      " 1   cc_num                 int64         \n",
      " 2   merchant               object        \n",
      " 3   category               object        \n",
      " 4   amt                    float64       \n",
      " 5   gender                 object        \n",
      " 6   lat                    float64       \n",
      " 7   long                   float64       \n",
      " 8   city_pop               int64         \n",
      " 9   job                    object        \n",
      " 10  unix_time              int64         \n",
      " 11  merch_lat              float64       \n",
      " 12  merch_long             float64       \n",
      " 13  is_fraud               int64         \n",
      " 14  age                    int32         \n",
      " 15  hour                   int32         \n",
      " 16  month                  int32         \n",
      " 17  day_of_week            int32         \n",
      " 18  distance               float64       \n",
      " 19  amt_vs_category_avg    float64       \n",
      "dtypes: datetime64[ns](1), float64(7), int32(4), int64(4), object(4)\n",
      "memory usage: 254.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Encoding object columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoders saved at: D:\\Data Science\\Big Data Technology\\Project\\Streaming-Fraud-Detection\\Streaming-Fraud-Detection\\Encoder\\LE_model_v1.pkl\n"
     ]
    }
   ],
   "source": [
    "encoder_dir = r\"D:\\Data Science\\Big Data Technology\\Project\\Streaming-Fraud-Detection\\Streaming-Fraud-Detection\\Encoder\"\n",
    "encoder_path = os.path.join(encoder_dir, \"LE_model_v1.pkl\")\n",
    "\n",
    "os.makedirs(encoder_dir, exist_ok=True)\n",
    "\n",
    "cols = ['merchant', 'category', 'gender', 'job']\n",
    "\n",
    "def encode(df):\n",
    "    df_obj = df.select_dtypes(include=['object'])\n",
    "    encoders = {}\n",
    "    for col in cols:\n",
    "        encoder = LabelEncoder()\n",
    "        df[col + '_indexer'] = encoder.fit_transform(df[col])\n",
    "        encoders[col] = encoder\n",
    "    \n",
    "    with open(encoder_path, 'wb') as f:\n",
    "        pickle.dump(encoders, f)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = encode(df)\n",
    "df = df.drop(cols, axis=1)\n",
    "\n",
    "print(f\"Encoders saved at: {encoder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1852394 entries, 0 to 1852393\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   trans_date_trans_time  datetime64[ns]\n",
      " 1   cc_num                 int64         \n",
      " 2   amt                    float64       \n",
      " 3   lat                    float64       \n",
      " 4   long                   float64       \n",
      " 5   city_pop               int64         \n",
      " 6   unix_time              int64         \n",
      " 7   merch_lat              float64       \n",
      " 8   merch_long             float64       \n",
      " 9   is_fraud               int64         \n",
      " 10  age                    int32         \n",
      " 11  hour                   int32         \n",
      " 12  month                  int32         \n",
      " 13  day_of_week            int32         \n",
      " 14  distance               float64       \n",
      " 15  amt_vs_category_avg    float64       \n",
      " 16  merchant_indexer       int64         \n",
      " 17  category_indexer       int64         \n",
      " 18  gender_indexer         int64         \n",
      " 19  job_indexer            int64         \n",
      "dtypes: datetime64[ns](1), float64(7), int32(4), int64(8)\n",
      "memory usage: 254.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Splitting Data intro Training and Testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1481916, 20)\n",
      "Testing set shape: (370478, 20)\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(df, test_size=0.2):\n",
    "    # Shuffle the dataframe\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # Calculate the number of test samples\n",
    "    test_count = int(len(df) * test_size)\n",
    "    \n",
    "    # Split the dataframe\n",
    "    df_train = df[:-test_count]\n",
    "    df_test = df[-test_count:]\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "# Perform the split\n",
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "# Display the shapes of the resulting dataframes\n",
    "print(f\"Training set shape: {df_train.shape}\")\n",
    "print(f\"Testing set shape: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in df.columns if col not in [\"trans_date_trans_time\", \"is_fraud\"]]\n",
    "target_col = \"is_fraud\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[feature_cols]\n",
    "y_train = df_train[target_col]\n",
    "\n",
    "X_test = df_test[feature_cols]\n",
    "y_test = df_test[target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. OverSampling (Process Imbalanced Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rule of thumb is: never mess up with your test set. Always split into test and train sets BEFORE trying oversampling/undersampling techniques!\n",
    "\n",
    "Oversampling before splitting the data can allow the exact same observations to be present in both the test and train sets. This can allow model to simply memorize specific data points and cause overfitting and poor generalization to the test data. Data leakage can cause you to create overly optimistic if not completely invalid predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://dataaspirant.com/wp-content/uploads/2020/08/10-oversampling.png)\n",
    "Picture Credit: https://dataaspirant.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data Science\\Big Data Technology\\Project\\Streaming-Fraud-Detection\\Streaming-Fraud-Detection\\venv\\lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature/label dataset for training before applying SMOTE:  (1481916, 18) (1481916,)\n",
      "Feature/label dataset for training after applying SMOTE:  (2948444, 18) (2948444,)\n",
      "Distribution of label values after applying SMOTE:\n",
      " is_fraud\n",
      "0    1474222\n",
      "1    1474222\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "print('Feature/label dataset for training before applying SMOTE: ', X_train.shape, y_train.shape)\n",
    "print('Feature/label dataset for training after applying SMOTE: ', X_train_smote.shape, y_train_smote.shape)\n",
    "print('Distribution of label values after applying SMOTE:\\n',pd.Series(y_train_smote).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Building Model (Spark ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"Streaming Fraud Detection\") \\\n",
    "        .config(\"spark.executor.memory\", \"16g\").config(\"spark.executor.cores\", \"4\") \\\n",
    "        .config(\"spark.task.cpus\", \"1\").config(\"spark.driver.memory\", \"8g\") \\\n",
    "        .config(\"spark.driver.cores\", \"4\").config(\"spark.executor.resource.gpu.amount\", \"1\") \\\n",
    "        .config(\"spark.executor.resource.gpu.discoveryScript\", \"/usr/bin/nvidia-smi\") \\\n",
    "        .config(\"spark.rapids.sql.enabled\", \"true\") \\\n",
    "        .config(\"spark.rapids.memory.pinnedPool.size\", \"2G\") \\\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = pd.DataFrame(X_train_smote, columns=X_train.columns)\n",
    "pandas_df['is_fraud'] = y_train_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cc_num</th>\n",
       "      <th>amt</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>age</th>\n",
       "      <th>hour</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>distance</th>\n",
       "      <th>amt_vs_category_avg</th>\n",
       "      <th>merchant_indexer</th>\n",
       "      <th>category_indexer</th>\n",
       "      <th>gender_indexer</th>\n",
       "      <th>job_indexer</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5359543825610251</td>\n",
       "      <td>59.91</td>\n",
       "      <td>45.7801</td>\n",
       "      <td>-111.1439</td>\n",
       "      <td>18182</td>\n",
       "      <td>1379488419</td>\n",
       "      <td>45.274075</td>\n",
       "      <td>-111.649432</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>42.701449</td>\n",
       "      <td>0.943802</td>\n",
       "      <td>285</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5540636818935089</td>\n",
       "      <td>3.96</td>\n",
       "      <td>42.6911</td>\n",
       "      <td>-71.1605</td>\n",
       "      <td>76383</td>\n",
       "      <td>1386265705</td>\n",
       "      <td>43.356278</td>\n",
       "      <td>-71.008959</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>46.554334</td>\n",
       "      <td>0.050186</td>\n",
       "      <td>284</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2720894374956739</td>\n",
       "      <td>51.17</td>\n",
       "      <td>42.5978</td>\n",
       "      <td>-82.8823</td>\n",
       "      <td>16305</td>\n",
       "      <td>1339759484</td>\n",
       "      <td>42.372483</td>\n",
       "      <td>-83.508020</td>\n",
       "      <td>92</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>35.549179</td>\n",
       "      <td>0.806115</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>374</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6011438889172900</td>\n",
       "      <td>2.06</td>\n",
       "      <td>34.2853</td>\n",
       "      <td>-91.3336</td>\n",
       "      <td>5161</td>\n",
       "      <td>1377816625</td>\n",
       "      <td>33.833389</td>\n",
       "      <td>-91.158293</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>32.731000</td>\n",
       "      <td>0.026107</td>\n",
       "      <td>531</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60495593109</td>\n",
       "      <td>6.58</td>\n",
       "      <td>32.7699</td>\n",
       "      <td>-96.7430</td>\n",
       "      <td>1263321</td>\n",
       "      <td>1343231435</td>\n",
       "      <td>32.458643</td>\n",
       "      <td>-96.577001</td>\n",
       "      <td>77</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>23.531950</td>\n",
       "      <td>0.058870</td>\n",
       "      <td>318</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cc_num    amt      lat      long  city_pop   unix_time  \\\n",
       "0  5359543825610251  59.91  45.7801 -111.1439     18182  1379488419   \n",
       "1  5540636818935089   3.96  42.6911  -71.1605     76383  1386265705   \n",
       "2  2720894374956739  51.17  42.5978  -82.8823     16305  1339759484   \n",
       "3  6011438889172900   2.06  34.2853  -91.3336      5161  1377816625   \n",
       "4       60495593109   6.58  32.7699  -96.7430   1263321  1343231435   \n",
       "\n",
       "   merch_lat  merch_long  age  hour  month  day_of_week   distance  \\\n",
       "0  45.274075 -111.649432   45     7      9            4  42.701449   \n",
       "1  43.356278  -71.008959   35    17     12            5  46.554334   \n",
       "2  42.372483  -83.508020   92    11      6            5  35.549179   \n",
       "3  33.833389  -91.158293   27    22      8            5  32.731000   \n",
       "4  32.458643  -96.577001   77    15      7            3  23.531950   \n",
       "\n",
       "   amt_vs_category_avg  merchant_indexer  category_indexer  gender_indexer  \\\n",
       "0             0.943802               285                 2               1   \n",
       "1             0.050186               284                12               1   \n",
       "2             0.806115                24                 2               0   \n",
       "3             0.026107               531                12               0   \n",
       "4             0.058870               318                13               1   \n",
       "\n",
       "   job_indexer  is_fraud  \n",
       "0          163         0  \n",
       "1          216         0  \n",
       "2          374         0  \n",
       "3          147         0  \n",
       "4          460         0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2948444 entries, 0 to 2948443\n",
      "Data columns (total 19 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   cc_num               int64  \n",
      " 1   amt                  float64\n",
      " 2   lat                  float64\n",
      " 3   long                 float64\n",
      " 4   city_pop             int64  \n",
      " 5   unix_time            int64  \n",
      " 6   merch_lat            float64\n",
      " 7   merch_long           float64\n",
      " 8   age                  int32  \n",
      " 9   hour                 int32  \n",
      " 10  month                int32  \n",
      " 11  day_of_week          int32  \n",
      " 12  distance             float64\n",
      " 13  amt_vs_category_avg  float64\n",
      " 14  merchant_indexer     int64  \n",
      " 15  category_indexer     int64  \n",
      " 16  gender_indexer       int64  \n",
      " 17  job_indexer          int64  \n",
      " 18  is_fraud             int64  \n",
      "dtypes: float64(7), int32(4), int64(8)\n",
      "memory usage: 382.4 MB\n"
     ]
    }
   ],
   "source": [
    "pandas_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.createDataFrame(pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "Output column features already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m feature_cols \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m spark_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_fraud\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      2\u001b[0m assembler \u001b[38;5;241m=\u001b[39m VectorAssembler(inputCols\u001b[38;5;241m=\u001b[39mfeature_cols, outputCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m spark_df \u001b[38;5;241m=\u001b[39m \u001b[43massembler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspark_df\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Data Science\\Big Data Technology\\Project\\Streaming-Fraud-Detection\\Streaming-Fraud-Detection\\venv\\lib\\site-packages\\pyspark\\ml\\base.py:262\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_transform(dataset)\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be a param map but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[1;32md:\\Data Science\\Big Data Technology\\Project\\Streaming-Fraud-Detection\\Streaming-Fraud-Detection\\venv\\lib\\site-packages\\pyspark\\ml\\wrapper.py:398\u001b[0m, in \u001b[0;36mJavaTransformer._transform\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[1;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m, dataset\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[1;32md:\\Data Science\\Big Data Technology\\Project\\Streaming-Fraud-Detection\\Streaming-Fraud-Detection\\venv\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32md:\\Data Science\\Big Data Technology\\Project\\Streaming-Fraud-Detection\\Streaming-Fraud-Detection\\venv\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: Output column features already exists."
     ]
    }
   ],
   "source": [
    "feature_cols = [col for col in spark_df.columns if col != \"is_fraud\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "spark_df = assembler.transform(spark_df).select(\"features\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = spark_df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"is_fraud\",\n",
    "    numTrees=100,        \n",
    "    maxDepth=5,        \n",
    "    impurity=\"gini\",        \n",
    "    seed=42,\n",
    "    subsamplingRate=0.8   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "label does not exist. Available: cc_num, amt, lat, long, city_pop, unix_time, merch_lat, merch_long, age, hour, month, day_of_week, distance, amt_vs_category_avg, merchant_indexer, category_indexer, gender_indexer, job_indexer, is_fraud, features",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Data Science\\Big Data Technology\\Project\\Streaming-Fraud-Detection\\Streaming-Fraud-Detection\\venv\\lib\\site-packages\\pyspark\\ml\\base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[0;32m    210\u001b[0m     )\n",
      "File \u001b[1;32md:\\Data Science\\Big Data Technology\\Project\\Streaming-Fraud-Detection\\Streaming-Fraud-Detection\\venv\\lib\\site-packages\\pyspark\\ml\\wrapper.py:381\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JM:\n\u001b[1;32m--> 381\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n",
      "File \u001b[1;32md:\\Data Science\\Big Data Technology\\Project\\Streaming-Fraud-Detection\\Streaming-Fraud-Detection\\venv\\lib\\site-packages\\pyspark\\ml\\wrapper.py:378\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[1;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Data Science\\Big Data Technology\\Project\\Streaming-Fraud-Detection\\Streaming-Fraud-Detection\\venv\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32md:\\Data Science\\Big Data Technology\\Project\\Streaming-Fraud-Detection\\Streaming-Fraud-Detection\\venv\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: label does not exist. Available: cc_num, amt, lat, long, city_pop, unix_time, merch_lat, merch_long, age, hour, month, day_of_week, distance, amt_vs_category_avg, merchant_indexer, category_indexer, gender_indexer, job_indexer, is_fraud, features"
     ]
    }
   ],
   "source": [
    "model = rf.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
