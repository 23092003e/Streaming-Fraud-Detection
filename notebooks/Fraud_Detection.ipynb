{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.sql.types import DoubleType\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FraudDetection\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.csv(r\"D:\\Data Science\\Big Data Technology\\Project\\Streaming-Fraud-Detection\\Streaming-Fraud-Detection\\data\\raw\\fraudTrain.csv\", header=True, inferSchema=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance use UDF\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    return geodesic((lat1, lon1), (lat2, lon2)).km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_udf = F.udf(calculate_distance, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"distance\", distance_udf(\"lat\", \"long\", \"merch_lat\", \"merch_long\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the transaction date to datetime\n",
    "df = df.withColumn(\"trans_date\", F.to_timestamp(\"trans_date_trans_time\")) \\\n",
    "       .withColumn(\"hour\", F.hour(\"trans_date\")) \\\n",
    "       .withColumn(\"day_of_week\", F.dayofweek(\"trans_date\")) \\\n",
    "       .withColumn(\"month\", F.month(\"trans_date\")) \\\n",
    "       .withColumn(\"age\", F.year(\"trans_date\") - F.year(\"dob\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns for modeling in Spark\n",
    "df = df.drop('first', 'last', 'street', 'city', 'state', 'zip', 'trans_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount vs average amount by category\n",
    "windowSpec = Window.partitionBy('category')\n",
    "\n",
    "# Calculate amt_vs_category_avg\n",
    "df = df.withColumn(\n",
    "    'amt_vs_category_avg',\n",
    "    F.col('amt') / F.avg('amt').over(windowSpec)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoding object columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\"merchant\", \"category\", \"gender\", \"job\"]\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col+\"_index\") for col in categorical_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Splitting Data intro Training and Testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size=0.2):\n",
    "    # Shuffle the dataframe\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # Calculate the number of test samples\n",
    "    test_count = int(len(df) * test_size)\n",
    "    \n",
    "    # Split the dataframe\n",
    "    df_train = df[:-test_count]\n",
    "    df_test = df[-test_count:]\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "# Perform the split\n",
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "# Display the shapes of the resulting dataframes\n",
    "print(f\"Training set shape: {df_train.shape}\")\n",
    "print(f\"Testing set shape: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in df.columns if col not in [\"trans_date_trans_time\", \"is_fraud\"]]\n",
    "target_col = \"is_fraud\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[feature_cols]\n",
    "y_train = df_train[target_col]\n",
    "\n",
    "X_test = df_test[feature_cols]\n",
    "y_test = df_test[target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. OverSampling (Process Imbalanced Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rule of thumb is: never mess up with your test set. Always split into test and train sets BEFORE trying oversampling/undersampling techniques!\n",
    "\n",
    "Oversampling before splitting the data can allow the exact same observations to be present in both the test and train sets. This can allow model to simply memorize specific data points and cause overfitting and poor generalization to the test data. Data leakage can cause you to create overly optimistic if not completely invalid predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://dataaspirant.com/wp-content/uploads/2020/08/10-oversampling.png)\n",
    "Picture Credit: https://dataaspirant.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "print('Feature/label dataset for training before applying SMOTE: ', X_train.shape, y_train.shape)\n",
    "print('Feature/label dataset for training after applying SMOTE: ', X_train_smote.shape, y_train_smote.shape)\n",
    "print('Distribution of label values after applying SMOTE:\\n',pd.Series(y_train_smote).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Building Model (Spark ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"Streaming Fraud Detection\") \\\n",
    "        .config(\"spark.executor.memory\", \"16g\").config(\"spark.executor.cores\", \"4\") \\\n",
    "        .config(\"spark.task.cpus\", \"1\").config(\"spark.driver.memory\", \"8g\") \\\n",
    "        .config(\"spark.driver.cores\", \"4\").config(\"spark.executor.resource.gpu.amount\", \"1\") \\\n",
    "        .config(\"spark.executor.resource.gpu.discoveryScript\", \"/usr/bin/nvidia-smi\") \\\n",
    "        .config(\"spark.rapids.sql.enabled\", \"true\") \\\n",
    "        .config(\"spark.rapids.memory.pinnedPool.size\", \"2G\") \\\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = pd.DataFrame(X_train_smote, columns=X_train.columns)\n",
    "pandas_df['is_fraud'] = y_train_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.createDataFrame(pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in spark_df.columns if col != \"is_fraud\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "spark_df = assembler.transform(spark_df).select(\"features\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
