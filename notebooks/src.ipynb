{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, when, mean,expr, avg, stddev\n",
    "from pyspark.sql.functions import lag, coalesce, lit\n",
    "from pyspark.sql.functions import to_date, date_format, to_timestamp\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, unix_timestamp\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "True\n",
      "NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)  # Kiểm tra phiên bản PyTorch\n",
    "print(torch.cuda.is_available())  # Kiểm tra GPU đã hoạt động chưa\n",
    "print(torch.cuda.get_device_name(0))  # In tên GPU của bạn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Streaming Fraud Detection System\") \\\n",
    "    .getOrCreate()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r'D:/Data Science/Big Data Technology/Project/Streaming-Fraud-Detection/Streaming-Fraud-Detection/data/raw/fraudTrain.csv'\n",
    "test_path = r'D:/Data Science/Big Data Technology/Project/Streaming-Fraud-Detection/Streaming-Fraud-Detection/data/raw/fraudTest.csv'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = spark.read.csv(train_path, header=True, inferSchema=True)\n",
    "test_data = spark.read.csv(test_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------+----------------+--------------------+-------------+------+---------+-------+------+--------------------+--------------+-----+-----+-------+---------+--------+--------------------+----------+--------------------+----------+------------------+-----------+--------+\n",
      "|_c0|trans_date_trans_time|          cc_num|            merchant|     category|   amt|    first|   last|gender|              street|          city|state|  zip|    lat|     long|city_pop|                 job|       dob|           trans_num| unix_time|         merch_lat| merch_long|is_fraud|\n",
      "+---+---------------------+----------------+--------------------+-------------+------+---------+-------+------+--------------------+--------------+-----+-----+-------+---------+--------+--------------------+----------+--------------------+----------+------------------+-----------+--------+\n",
      "|  0|  2019-01-01 00:00:18|2703186189652095|fraud_Rippin, Kub...|     misc_net|  4.97| Jennifer|  Banks|     F|      561 Perry Cove|Moravian Falls|   NC|28654|36.0788| -81.1781|    3495|Psychologist, cou...|1988-03-09|0b242abb623afc578...|1325376018|         36.011293| -82.048315|       0|\n",
      "|  1|  2019-01-01 00:00:44|    630423337322|fraud_Heller, Gut...|  grocery_pos|107.23|Stephanie|   Gill|     F|43039 Riley Green...|        Orient|   WA|99160|48.8878|-118.2105|     149|Special education...|1978-06-21|1f76529f857473494...|1325376044|49.159046999999994|-118.186462|       0|\n",
      "|  2|  2019-01-01 00:00:51|  38859492057661|fraud_Lind-Buckridge|entertainment|220.11|   Edward|Sanchez|     M|594 White Dale Su...|    Malad City|   ID|83252|42.1808| -112.262|    4154|Nature conservati...|1962-01-19|a1a22d70485983eac...|1325376051|         43.150704|-112.154481|       0|\n",
      "|  3|  2019-01-01 00:01:16|3534093764340240|fraud_Kutch, Herm...|gas_transport|  45.0|   Jeremy|  White|     M|9443 Cynthia Cour...|       Boulder|   MT|59632|46.2306|-112.1138|    1939|     Patent attorney|1967-01-12|6b849c168bdad6f86...|1325376076|         47.034331|-112.561071|       0|\n",
      "|  4|  2019-01-01 00:03:06| 375534208663984| fraud_Keeling-Crist|     misc_pos| 41.96|    Tyler| Garcia|     M|    408 Bradley Rest|      Doe Hill|   VA|24433|38.4207| -79.4629|      99|Dance movement ps...|1986-03-28|a41d7549acf907893...|1325376186|         38.674999| -78.632459|       0|\n",
      "+---+---------------------+----------------+--------------------+-------------+------+---------+-------+------+--------------------+--------------+-----+-----+-------+---------+--------+--------------------+----------+--------------------+----------+------------------+-----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = train_data.union(test_data)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- trans_date_trans_time: timestamp (nullable = true)\n",
      " |-- cc_num: long (nullable = true)\n",
      " |-- merchant: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- amt: double (nullable = true)\n",
      " |-- first: string (nullable = true)\n",
      " |-- last: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- street: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- zip: integer (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- city_pop: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- dob: date (nullable = true)\n",
      " |-- trans_num: string (nullable = true)\n",
      " |-- unix_time: integer (nullable = true)\n",
      " |-- merch_lat: double (nullable = true)\n",
      " |-- merch_long: double (nullable = true)\n",
      " |-- is_fraud: integer (nullable = true)\n",
      "\n",
      "Rows: 1852394, Columns: 23\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "print(f\"Rows: {df.count()}, Columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+-------------------+-------------+------------------+-------+-------+-------+--------------------+-------+-------+------------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-----------------+------------------+--------------------+\n",
      "|summary|               _c0|              cc_num|           merchant|     category|               amt|  first|   last| gender|              street|   city|  state|               zip|              lat|              long|         city_pop|               job|           trans_num|           unix_time|        merch_lat|        merch_long|            is_fraud|\n",
      "+-------+------------------+--------------------+-------------------+-------------+------------------+-------+-------+-------+--------------------+-------+-------+------------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-----------------+------------------+--------------------+\n",
      "|  count|           1852394|             1852394|            1852394|      1852394|           1852394|1852394|1852394|1852394|             1852394|1852394|1852394|           1852394|          1852394|           1852394|          1852394|           1852394|             1852394|             1852394|          1852394|           1852394|             1852394|\n",
      "|   mean| 537193.4400003455|4.173860383937233...|               NULL|         NULL|   70.063567475386|   NULL|   NULL|   NULL|                NULL|   NULL|   NULL| 48813.25819075207| 38.5393109792529|-90.22783229070141|88643.67450931066|              NULL|            Infinity|1.3586742188343642E9|38.53897596705942|-90.22793950913788|0.005210014716091717|\n",
      "| stddev|366910.96048312774|1.309115265318734...|               NULL|         NULL|159.25397477398343|   NULL|   NULL|   NULL|                NULL|   NULL|   NULL|26881.845965862834|5.071470391380579|13.747894882569089|  301487.61834365|              NULL|                 NaN| 1.819508138755659E7|5.105603877592813|13.759692112582863| 0.07199217499619144|\n",
      "|    min|                 0|         60416207185|fraud_Abbott-Rogahn|entertainment|               1.0|  Aaron| Abbott|      F|  000 Jennifer Mills|Achille|     AK|              1257|          20.0271|         -165.6723|               23|Academic librarian|00000ecad06b03d3a...|          1325376018|        19.027422|       -166.671575|                   0|\n",
      "|    max|           1296674| 4992346398065154184|   fraud_Zulauf LLC|       travel|           28948.9|Zachary| Zuniga|      M|99736 Rose Shoals...|Zavalla|     WY|             99921|          66.6933|          -67.9503|          2906700|            Writer|ffffef9d89e7d02d8...|          1388534374|        67.510267|        -66.950902|                   1|\n",
      "+-------+------------------+--------------------+-------------------+-------------+------------------+-------+-------+-------+--------------------+-------+-------+------------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-----------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------+------+--------+--------+---+-----+----+------+------+----+-----+---+---+----+--------+---+---+---------+---------+---------+----------+--------+\n",
      "|_c0|trans_date_trans_time|cc_num|merchant|category|amt|first|last|gender|street|city|state|zip|lat|long|city_pop|job|dob|trans_num|unix_time|merch_lat|merch_long|is_fraud|\n",
      "+---+---------------------+------+--------+--------+---+-----+----+------+------+----+-----+---+---+----+--------+---+---+---------+---------+---------+----------+--------+\n",
      "|  0|                    0|     0|       0|       0|  0|    0|   0|     0|     0|   0|    0|  0|  0|   0|       0|  0|  0|        0|        0|        0|         0|       0|\n",
      "+---+---------------------+------+--------+--------+---+-----+----+------+------+----+-----+---+---+----+--------+---+---+---------+---------+---------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "missing_values.show()\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, year, month, dayofmonth, hour, to_date\n",
    "\n",
    "df = df.withColumn(\"trans_date_trans_time\", to_timestamp(col(\"trans_date_trans_time\"), \"dd/MM/yyyy HH:mm:ss\"))\n",
    "df = df.withColumn(\"dob\", to_date(col(\"dob\"), \"yyyy-MM-dd\"))\n",
    "\n",
    "df = df.withColumn(\"age\", year(col(\"trans_date_trans_time\")) - year(col(\"dob\"))) \\\n",
    "       .withColumn(\"hour\", hour(col(\"trans_date_trans_time\"))) \\\n",
    "       .withColumn(\"day\", dayofmonth(col(\"trans_date_trans_time\"))) \\\n",
    "       .withColumn(\"month\", month(col(\"trans_date_trans_time\")))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------+----------------+--------------------+-------------+------+---------+-------+------+--------------------+--------------+-----+-----+-------+---------+--------+--------------------+----------+--------------------+----------+------------------+-----------+--------+---+----+---+-----+\n",
      "|_c0|trans_date_trans_time|          cc_num|            merchant|     category|   amt|    first|   last|gender|              street|          city|state|  zip|    lat|     long|city_pop|                 job|       dob|           trans_num| unix_time|         merch_lat| merch_long|is_fraud|age|hour|day|month|\n",
      "+---+---------------------+----------------+--------------------+-------------+------+---------+-------+------+--------------------+--------------+-----+-----+-------+---------+--------+--------------------+----------+--------------------+----------+------------------+-----------+--------+---+----+---+-----+\n",
      "|  0|  2019-01-01 00:00:18|2703186189652095|fraud_Rippin, Kub...|     misc_net|  4.97| Jennifer|  Banks|     F|      561 Perry Cove|Moravian Falls|   NC|28654|36.0788| -81.1781|    3495|Psychologist, cou...|1988-03-09|0b242abb623afc578...|1325376018|         36.011293| -82.048315|       0| 31|   0|  1|    1|\n",
      "|  1|  2019-01-01 00:00:44|    630423337322|fraud_Heller, Gut...|  grocery_pos|107.23|Stephanie|   Gill|     F|43039 Riley Green...|        Orient|   WA|99160|48.8878|-118.2105|     149|Special education...|1978-06-21|1f76529f857473494...|1325376044|49.159046999999994|-118.186462|       0| 41|   0|  1|    1|\n",
      "|  2|  2019-01-01 00:00:51|  38859492057661|fraud_Lind-Buckridge|entertainment|220.11|   Edward|Sanchez|     M|594 White Dale Su...|    Malad City|   ID|83252|42.1808| -112.262|    4154|Nature conservati...|1962-01-19|a1a22d70485983eac...|1325376051|         43.150704|-112.154481|       0| 57|   0|  1|    1|\n",
      "|  3|  2019-01-01 00:01:16|3534093764340240|fraud_Kutch, Herm...|gas_transport|  45.0|   Jeremy|  White|     M|9443 Cynthia Cour...|       Boulder|   MT|59632|46.2306|-112.1138|    1939|     Patent attorney|1967-01-12|6b849c168bdad6f86...|1325376076|         47.034331|-112.561071|       0| 52|   0|  1|    1|\n",
      "|  4|  2019-01-01 00:03:06| 375534208663984| fraud_Keeling-Crist|     misc_pos| 41.96|    Tyler| Garcia|     M|    408 Bradley Rest|      Doe Hill|   VA|24433|38.4207| -79.4629|      99|Dance movement ps...|1986-03-28|a41d7549acf907893...|1325376186|         38.674999| -78.632459|       0| 33|   0|  1|    1|\n",
      "+---+---------------------+----------------+--------------------+-------------+------+---------+-------+------+--------------------+--------------+-----+-----+-------+---------+--------+--------------------+----------+--------------------+----------+------------------+-----------+--------+---+----+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.orderBy(\"trans_date_trans_time\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------+----------------+--------------------+-------------+------+------+-------+---------+--------+--------------------+----------+----------+------------------+-----------+--------+---+----+---+-----+\n",
      "|_c0|trans_date_trans_time|          cc_num|            merchant|     category|   amt|gender|    lat|     long|city_pop|                 job|       dob| unix_time|         merch_lat| merch_long|is_fraud|age|hour|day|month|\n",
      "+---+---------------------+----------------+--------------------+-------------+------+------+-------+---------+--------+--------------------+----------+----------+------------------+-----------+--------+---+----+---+-----+\n",
      "|  0|  2019-01-01 00:00:18|2703186189652095|fraud_Rippin, Kub...|     misc_net|  4.97|     F|36.0788| -81.1781|    3495|Psychologist, cou...|1988-03-09|1325376018|         36.011293| -82.048315|       0| 31|   0|  1|    1|\n",
      "|  1|  2019-01-01 00:00:44|    630423337322|fraud_Heller, Gut...|  grocery_pos|107.23|     F|48.8878|-118.2105|     149|Special education...|1978-06-21|1325376044|49.159046999999994|-118.186462|       0| 41|   0|  1|    1|\n",
      "|  2|  2019-01-01 00:00:51|  38859492057661|fraud_Lind-Buckridge|entertainment|220.11|     M|42.1808| -112.262|    4154|Nature conservati...|1962-01-19|1325376051|         43.150704|-112.154481|       0| 57|   0|  1|    1|\n",
      "|  3|  2019-01-01 00:01:16|3534093764340240|fraud_Kutch, Herm...|gas_transport|  45.0|     M|46.2306|-112.1138|    1939|     Patent attorney|1967-01-12|1325376076|         47.034331|-112.561071|       0| 52|   0|  1|    1|\n",
      "|  4|  2019-01-01 00:03:06| 375534208663984| fraud_Keeling-Crist|     misc_pos| 41.96|     M|38.4207| -79.4629|      99|Dance movement ps...|1986-03-28|1325376186|         38.674999| -78.632459|       0| 33|   0|  1|    1|\n",
      "+---+---------------------+----------------+--------------------+-------------+------+------+-------+---------+--------+--------------------+----------+----------+------------------+-----------+--------+---+----+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['first', 'last', 'street', 'city', 'state', 'zip', 'trans_num']\n",
    "df = df.drop(*columns_to_drop)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder categorical (StringIndexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------+----------------+------+-------+---------+--------+----------+----------+------------------+-----------+--------+---+----+---+-----+----------------+----------------+--------------+-----------+\n",
      "|_c0|trans_date_trans_time|          cc_num|   amt|    lat|     long|city_pop|       dob| unix_time|         merch_lat| merch_long|is_fraud|age|hour|day|month|merchant_Indexer|category_Indexer|gender_Indexer|job_Indexer|\n",
      "+---+---------------------+----------------+------+-------+---------+--------+----------+----------+------------------+-----------+--------+---+----+---+-----+----------------+----------------+--------------+-----------+\n",
      "|  0|  2019-01-01 00:00:18|2703186189652095|  4.97|36.0788| -81.1781|    3495|1988-03-09|1325376018|         36.011293| -82.048315|       0| 31|   0|  1|    1|           584.0|            11.0|           0.0|      129.0|\n",
      "|  1|  2019-01-01 00:00:44|    630423337322|107.23|48.8878|-118.2105|     149|1978-06-21|1325376044|49.159046999999994|-118.186462|       0| 41|   0|  1|    1|           104.0|             1.0|           0.0|       64.0|\n",
      "|  2|  2019-01-01 00:00:51|  38859492057661|220.11|42.1808| -112.262|    4154|1962-01-19|1325376051|         43.150704|-112.154481|       0| 57|   0|  1|    1|           365.0|             6.0|           1.0|      426.0|\n",
      "|  3|  2019-01-01 00:01:16|3534093764340240|  45.0|46.2306|-112.1138|    1939|1967-01-12|1325376076|         47.034331|-112.561071|       0| 52|   0|  1|    1|            38.0|             0.0|           1.0|      205.0|\n",
      "|  4|  2019-01-01 00:03:06| 375534208663984| 41.96|38.4207| -79.4629|      99|1986-03-28|1325376186|         38.674999| -78.632459|       0| 33|   0|  1|    1|           520.0|            10.0|           1.0|      284.0|\n",
      "+---+---------------------+----------------+------+-------+---------+--------+----------+----------+------------------+-----------+--------+---+----+---+-----+----------------+----------------+--------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "categorical_cols = ['merchant', 'category', 'gender', 'job']\n",
    "\n",
    "for col_name in categorical_cols:\n",
    "    indexer = StringIndexer(inputCol=col_name, outputCol=f\"{col_name}_Indexer\")\n",
    "    df = indexer.fit(df).transform(df)\n",
    "    \n",
    "df = df.drop(*categorical_cols)\n",
    "    \n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting Into Training and Testing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set row count: 1481915\n",
      "Testing set row count: 370479\n"
     ]
    }
   ],
   "source": [
    "split_index = int(df.count()* 0.8)\n",
    "train_df  = df.limit(split_index)\n",
    "test_df = df.subtract(train_df)\n",
    "\n",
    "# Display row counts of the resulting DataFrames to verify the split\n",
    "print(f\"Training set row count: {train_df.count()}\")\n",
    "print(f\"Testing set row count: {test_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [ \"merchant_Indexer\", \"category_Indexer\", \"amt\", \"gender_Indexer\", \"lat\", \"long\", \"city_pop\", \"job_Indexer\", \"unix_time\", \"merch_lat\", \"merch_long\", \"age\", \"hour\", \"day\", \"month\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------------+--------+\n",
      "|trans_date_trans_time|     scaled_features|is_fraud|\n",
      "+---------------------+--------------------+--------+\n",
      "|  2019-01-01 00:00:18|[0.84393063583815...|       0|\n",
      "|  2019-01-01 00:00:44|[0.15028901734104...|       0|\n",
      "|  2019-01-01 00:00:51|[0.52745664739884...|       0|\n",
      "|  2019-01-01 00:01:16|[0.05491329479768...|       0|\n",
      "|  2019-01-01 00:03:06|[0.75144508670520...|       0|\n",
      "+---------------------+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import unix_timestamp\n",
    "\n",
    "# Convert the timestamp to a Unix timestamp (if not already).\n",
    "#df = df.withColumn(\"unix_time\", unix_timestamp(\"trans_date_trans_time\").cast(\"int\"))\n",
    "\n",
    "# Create a data processing pipeline.\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "pipeline = Pipeline(stages=[assembler, scaler])\n",
    "\n",
    "# Train the pipeline on the dataset.\n",
    "transformer = pipeline.fit(df)\n",
    "\n",
    "# Transform the data.\n",
    "df = transformer.transform(df).select(\"trans_date_trans_time\", \"scaled_features\", \"is_fraud\")\n",
    "train_set = transformer.transform(train_df).select(\"trans_date_trans_time\", \"scaled_features\", \"is_fraud\")\n",
    "test_set = transformer.transform(test_df).select(\"trans_date_trans_time\", \"scaled_features\", \"is_fraud\")\n",
    "\n",
    "train_set.show(5)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Logistic Regression Model\n",
    "logistic_regressor = LogisticRegression(\n",
    "    featuresCol='scaled_features', \n",
    "    labelCol='is_fraud'\n",
    ")\n",
    "\n",
    "# Use `BinaryClassificationEvaluator` instead of `RegressionEvaluator`.\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol='is_fraud', \n",
    "    rawPredictionCol='prediction', \n",
    "    metricName='areaUnderROC'\n",
    ")\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(logistic_regressor.regParam, [0.001, 0.01, 0.1]) \\\n",
    "    .addGrid(logistic_regressor.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .addGrid(logistic_regressor.maxIter, [50, 100, 300]) \\\n",
    "    .addGrid(logistic_regressor.tol, [1e-6, 1e-4, 1e-2]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation with numFolds=3\n",
    "crossval = CrossValidator(\n",
    "    estimator=logistic_regressor,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3\n",
    ")\n",
    "\n",
    "# Train the best model on the training set.\n",
    "cv_model = crossval.fit(train_set)\n",
    "\n",
    "# Retrieve the best model from Cross Validation.\n",
    "best_model = cv_model.bestModel\n",
    "\n",
    "print(\"Best Model Params:\")\n",
    "print(\"  Regularization Param (regParam):\", best_model.getRegParam())\n",
    "print(\"  ElasticNet Param (elasticNetParam):\", best_model.getElasticNetParam())\n",
    "print(\"  Maximum Iterations (maxIter):\", best_model.getMaxIter())\n",
    "print(\"  Tolerance (tol):\", best_model.getTol())\n",
    "print(\"  Threshold:\", best_model.getThreshold())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
